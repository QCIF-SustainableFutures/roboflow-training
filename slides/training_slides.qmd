---
title: "A Masterclass on Roboflow and Computer Vision"
format: clean-revealjs
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: Dr Sebastian Lopez Marcano
    orcid: 0000-0002-0814-2906
    email: s.lopezmarcano@qcif.edu.au
    affiliations: QCIF
date: last-modified
---

# Objectives and Overview

## Why this workshop
- WildObs
  - A national platform for camera trap monitoring. 
  - Primary Objective: Staff training - understand computer vision models. 
  - Secondary Objective: WildObs may want to use Roboflow tools (e.g.,Python SDK) for model development and model deployment.
- DETSI
  - QCIF is supporting DETSI to develop an -inhouse- solution for key QLD wildlife species. PSP Advance Qld project. 
  - Primary Objective: Get familiar with Roboflow and understand the theory behind computer vision models. Roboflow will be used to develop a computer vision model for DETSI.

::: {.callout-note}
DETSI will be contributing datasets to WildObs. DETSI intends to use WildObs. 
:::

## Modules Overview

- **Module 1**: AI, Deep Learning, and Computer Vision
- **Module 2**: Understanding the computer vision workflow
- **Module 3**: Building your model development dataset
- **Module 4**: Model training and evaluation
- **Module 5**: Model inference
- **Module 6**: Roboflow workflows

---

# Module 1: AI - DL - CV
:::: {.columns}

::: {.column width="40%"}
![A visual representation of AI, ML, DL, and CV](assets/1-s2.0-S0886779820306313-gr4.jpg)
:::

::: {.column width="60%"}
**What is Deep Learning?**

- A subset of Machine Learning to train neural networks and make predictions

**What is Computer Vision?**

- A field of AI that enables computers to interpret and understand visual information
- Key applications: classification, object detection and segmentation
:::

::::

## Computer vision tasks
- **Image Classification**: Assigns a label to an entire image (e.g., "cat", "dog")
- **Object Detection**: Identifies and localizes multiple objects within an image (e.g., "cat" at (x,y) coordinates, "dog" at (x,y) coordinates)

![](assets/img-classification_detection.png)

## CV tasks in the context of camera trap monitoring
![](assets/generic_ai_camera_trap_workflow.png)

---

# Module 2: Understanding the computer vision workflow
## Key Steps *‚ú®<span style="color:purple;">with the Roboflow sparkle</span>‚ú®*
- Objective and infrastructure
- Data collection and pre-processing
- <span style="color:purple;">Create account and project</span>
- Data splitting
- <span style="color:purple;">Data upload</span>
- <span style="color:purple;">Data annotation</span>
- <span style="color:purple;">Building your model development dataset</span>
- <span style="color:purple;">Model training</span>
- <span style="color:purple;">Model evaluation</span>
- <span style="color:purple;">Model inference</span> 
- Post-processing

## Objective and Infrastructure
- **Objective**: Define the problem you want to solve (e.g., species identification, behavior analysis)
  - How many classes?
  - What is the expected accuracy?
  - What is the long-term goal? 
- **Infrastructure**: Determine the hardware and software requirements for your project
  - GPU/CPU requirements
  - Storage capacity

## ü™úData collection and pre-processing
- **Data Collection**: Camera traps
- **Data Pre-processing**: Cleaning and preparing data for further analysis
  - Rename files 
  - Move files to appropriate folders

## <span style="color:purple;"> ü™úCreate account and project</span>
- Let's go to Roboflow!
- Create a Roboflow account
- Create a new project


## ü™ú Data Splitting Part 1
- Now we need data to add into our project
  - Model development dataset (e.g., training, validation, evaluation)
  - Inference dataset

::: {.callout-note}
Depending on the dataset size, model development can be between 10-20% of the total dataset.
:::

## Data Splitting Part 2 : Broad types of data selection
- General Computer Vision: Random selection
- Environmental Computer Vision: Targeted selection

::: {.callout-important}
The data splitting process is crucial and takes time. 
::: 

::: {.callout-important}
The model development dataset should be representative of the data that will be processed in the field / future
:::

## Data Splitting Part 3: Importance of metadata

:::: {.columns}
::: {.column width="33%"}
- Model trained on images from üèñÔ∏è will not be accurate when deployed in üèûÔ∏è
:::
::: {.column width="33%"}
- Model trained on images collected during ‚òÄÔ∏è hours will not be accurate when processing images collected at üåù
:::
::: {.column width="33%"}
- For a single location, a model trained on images collected in `year 1` will not be *accurate* when processing images collected in `year 2`
:::
::::

## Data Splitting Part 4: Relationship between objectives - metadata and data splitting
- This is why its important to determine your objectives at the beginning of the project 
- Questions that require answers?
  - How many classes?
  - How many ecosystems / locations?
  - How many seasons / years?

## Data Splitting Part 4: Relationship between objectives - metadata and data splitting
- How many classes?
  - 20 classes
- How many ecosystems / locations?
  - 3 ecosystems
- How many seasons / years?
  - 2 seasons

::: {.callout-tip}
Let's use a conservative 1,500 images per class 
:::
```markdown
| Ecosystem   | Year 1 | Year 2 | Total |
|-------------|--------|--------|-------|
| Ecosystem 1 | 250    | 250    | 500   |
| Ecosystem 2 | 250    | 250    | 500   |
| Ecosystem 3 | 250    | 250    | 500   |
| **Total**   | 750    | 750    | 1,500 |
```

## Data Splitting Part 5: How many images do I need?
![](assets/medium_guidelines_modeldevelopment.png){width=30%}

<span style="font-size:small;">https://joelnadarai.medium.com/the-art-of-choosing-the-right-number-of-images-for-your-computer-vision-project-6e45efd1efbf#:~:text=For%20fine%2Dtuning%20pre%2Dtrained,per%20class%20for%20detection%20tasks.</span> 

## Data Splitting Part 6: What to do with class imbalance?
- **Class imbalance**: When one class has significantly more images than another
- **Solutions**:
  - Merging classes
  - Data augmentation
  - Data filtering
  - Data collection

```markdown
| Class         | Number of Images | Notes                              |
|---------------|------------------|------------------------------------|
| Kangaroo      | 1,200            | Overrepresented                   |
| Koala         | 300              | Underrepresented                  |
| Emu           | 150              | Severely underrepresented          |
| Wombat        | 800              | Moderately represented            |
| Possum        | 100              | Severely underrepresented          |
| Dingo         | 600              | Balanced                          |
| Echidna       | 50               | Rarely detected                   |
| Cockatoo      | 1,000            | Overrepresented                   |
| Platypus      | 20               | Extremely rare                    |
| Wallaby       | 700              | Balanced                          |
```
---

# Module 3: Building your model development dataset

## Recap Steps *‚ú®<span style="color:purple;">with the Roboflow sparkle</span>‚ú®*

- Objective and infrastructure ‚úÖ
- Data collection and pre-processing ‚úÖ
- <span style="color:purple;">Create account and project</span> ‚úÖ
- Data splitting ‚úÖ
- <span style="color:purple;">Data upload</span> üëàüèº
- <span style="color:purple;">Data annotation</span>
- <span style="color:purple;">Building your model development dataset</span>
- <span style="color:purple;">Model training</span>
- <span style="color:purple;">Model evaluation</span>
- <span style="color:purple;">Model inference</span> 
- Post-processing

## ü™ú Data upload part 1
:::: {.columns}
::: {.column width="50%"}
- <span style="color:purple;">Upload images to Roboflow</span>
   - Batch Name üóíÔ∏è 
   - Tags üè∑Ô∏è
- Similar images from Object365
:::
::: {.column width="50%"}
- Upload images to Roboflow (Python SDK)

```{.python}
from roboflow import Roboflow

# Initialize the Roboflow object with your API key
rf = Roboflow(api_key="YOUR_PRIVATE_API_KEY")

# Retrieve your current workspace and project name
print(rf.workspace())

# Project:https://app.roboflow.com/my-workspace/my-project
workspaceId = 'my-workspace'
projectId = 'my-project'
project = rf.workspace(workspaceId).project(projectId)

# Upload the image to your project
project.upload("UPLOAD_IMAGE.jpg")
```
:::
::::

## Data upload part 2
::: {.callout-tip}
Upload images in batches that make sense for your project / later filtering analysis. **My tip**: upload images based on initial data splitting. 
:::

::: {.callout-tip}
Always keep an eye on your limit for `source images`. 
::: 

## ü™ú Data annotation part 1
![Annotation types](assets/annotation_types.png)

## Data annotation part 2
- <span style="color:purple;">Labelling images in Roboflow</span>
  - Auto Label
    - Grounding DINO
    - My Models (e.g., MegaDetector or SpeciesNet)
        - Roboflow trained models
        - Upload via API ‚≠êÔ∏è
    - Importance of confidene threshold when using zero-shot models
  - Manual Label

## Data annotation part 3
- <span style="color:purple;">Labelling images in Roboflow</span>
  - Auto Label
  - Manual Label
    - Review (Approve or Reject)
    - Manual bbox
    - Smart labelling
    - Bounding box prompting

:::{.callout-tip}
Label every relevant object in every image, even if it‚Äôs partially visible - Roboflow
:::

:::{.callout-important}
You can always import labels from other tools / models / projects for images into Roboflow
:::


## ü™ú Building your model development dataset
- **Training**: Used to train the model - 70% of model development data
- **Validation**: Used to tune hyperparameters and prevent overfitting - 10% of model development data
- **Evaluation**: Used to assess the model's performance on unseen data - 20% of data of model development

::: {.callout-tip}
**Reminder**: Upload images in batches that make sense for your project / later filtering analysis. **My tip**: upload images based on initial data splitting. 
:::

---

# Module 4: Model training and evaluation

## Recap Steps *‚ú®<span style="color:purple;">with the Roboflow sparkle</span>‚ú®*
- Objective and infrastructure ‚úÖ
- Data collection and pre-processing ‚úÖ
- <span style="color:purple;">Create account and project</span> ‚úÖ
- Data splitting ‚úÖ
- <span style="color:purple;">Data upload</span> ‚úÖ
- <span style="color:purple;">Data annotation</span> ‚úÖ
- <span style="color:purple;">Building your model development dataset</span> ‚úÖ
- <span style="color:purple;">Model training</span> üëàüèº
- <span style="color:purple;">Model evaluation</span>
- <span style="color:purple;">Model inference</span> 
- Post-processing

## <span style="color:purple;">ü™úModel training</span>

::::{.columns}
::: {.column width="50%"}
- Create a dataset version
  - Data augmentation
  - Data filtering
- Select a model architecture
  - Comments around RF-DETR
:::
::: {.column width="50%"}
### Download the dataset version (Python)
```{.python}
from google.colab import userdata
from roboflow import Roboflow

ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')

rf = Roboflow(api_key=ROBOFLOW_API_KEY)
project = rf.workspace("selencakmak").project("tumor-dj2a1")
version = project.version(1)
dataset = version.download("yolov8")
```
### Train the model (CLI)
```{.cli}
!yolo task=detect mode=train epochs=10 batch=32 plots=True \
model={HOME}/weights/yolov10n.pt \
data={dataset.location}/data.yaml
```
:::
::::

## ü™úModel validation - evaluation
- Two different things
- **Validation**: Assess the model's performance on the validation set during training
  - Monitor metrics like loss and accuracy
  - Adjust hyperparameters to improve performance
- **Evaluation**: Assess the model's performance on the evaluation set after training

## Model validation and evaluation - metrics
- **Precision**: The ratio of true positive predictions to the total predicted positives
- **Recall**: The ratio of true positive predictions to the total actual positives
- **F1 Score**: The harmonic mean of precision and recall

## Understanding validation and evaluation results
- Lets review these outputs in Roboflow

::: {.callout-note}
We will not be able to cover how to review these metrics in a programmatic environment
:::

# Module 5: Model inference
## Recap Steps *‚ú®<span style="color:purple;">with the Roboflow sparkle</span>‚ú®*
- Objective and infrastructure ‚úÖ
- Data collection and pre-processing ‚úÖ
- <span style="color:purple;">Create account and project</span> ‚úÖ
- Data splitting ‚úÖ
- <span style="color:purple;">Data upload</span> ‚úÖ
- <span style="color:purple;">Data annotation</span> ‚úÖ
- <span style="color:purple;">Building your model development dataset</span> ‚úÖ
- <span style="color:purple;">Model training</span> ‚úÖ
- <span style="color:purple;">Model evaluation</span> ‚úÖ
- <span style="color:purple;">Model inference</span> üëàüèº
- Post-processing

## <span style="color:purple;">ü™úModel inference</span>
- **Inference**: The process of using a trained model to make predictions on new, unseen data
- Let's use the Deployments tab in Roboflow to deploy our model

## ü™úPost-processing
- Not going to go in depth here
- Confidence threshold
- Non-max suppression

## Example Computer Vision Dataset

Below is an example of a classic computer vision dataset structure:

```markdown
| Filename     | Class      | xmin | xmax | ymin | ymax | Confidence |
|--------------|------------|------|------|------|------|------------|
| image1.jpg   | kangaroo   | 50   | 150  | 60   | 160  | 0.95       |
| image2.jpg   | possum     | 30   | 130  | 40   | 140  | 0.20       |
| image3.jpg   | bird       | 100  | 200  | 120  | 220  | 0.92       |
| image4.jpg   | cat        | 70   | 170  | 80   | 180  | 0.97       |
| image5.jpg   | dog        | 20   | 120  | 30   | 130  | 0.85       |
| image6.jpg   | bird       | 90   | 190  | 110  | 210  | 0.90       |
```

# Module 6: Roboflow workflows
## Workflows to assist development
